{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9534493,"sourceType":"datasetVersion","datasetId":5807006}],"dockerImageVersionId":30775,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport zipfile\n\n# Kaggle environment paths\ndataset_path = \"/kaggle/input/keras-multi-label/keras-multi-label\"  \n\n# Change directory to the unzipped dataset folder (if necessary)\ndataset_folder = \"/kaggle/input/keras-multi-label/keras-multi-label/dataset\"\nos.chdir(dataset_folder)\n\n# Verify files\nprint(\"[INFO] Dataset files:\", os.listdir(dataset_folder))","metadata":{"_uuid":"fb08c88d-8db3-4a64-8c56-d8563657764c","_cell_guid":"f3dfed9f-43aa-415c-8166-5da0ff18ac70","collapsed":false,"execution":{"iopub.status.busy":"2024-10-03T00:43:18.202045Z","iopub.execute_input":"2024-10-03T00:43:18.202646Z","iopub.status.idle":"2024-10-03T00:43:18.250629Z","shell.execute_reply.started":"2024-10-03T00:43:18.202591Z","shell.execute_reply":"2024-10-03T00:43:18.249386Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 1: Prepare Data (Image and Labels)**","metadata":{"_uuid":"ad7d732c-9b17-4310-89e0-9288baf2ae5f","_cell_guid":"28bd739a-302e-4b0e-adb3-7c870a606d02","trusted":true}},{"cell_type":"code","source":"# Import necessary libraries for data loading and preprocessing\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport numpy as np\nimport glob\n\n# Define image dimensions\nIMAGE_DIMS = (64, 64, 3)  # You can adjust this based on your use case\n\n# Initialize data and labels\ndata = []\nlabels = []\n\n# List of classes (subdirectories in the dataset)\nclass_names = [\"black_jeans\", \"blue_dress\", \"blue_jeans\", \"blue_shirt\", \"red_dress\", \"red_shirt\"]\n\n# Loop through each class (subdirectory)\nfor class_name in class_names:\n    image_paths = glob.glob(os.path.join(dataset_folder, class_name, \"*.jpg\"))  # Adjust extension if needed\n    for imagePath in image_paths:\n        # Load the image, resize it, and convert to array\n        image = load_img(imagePath, target_size=(IMAGE_DIMS[0], IMAGE_DIMS[1]))\n        image = img_to_array(image)\n        data.append(image)\n        \n        # Add the corresponding label (class name)\n        labels.append([class_name])\n\n# Convert data to a numpy array and normalize it\ndata = np.array(data, dtype=\"float\") / 255.0\n\n# Convert labels to numpy array\nlabels = np.array(labels)\n\n# Display the number of images loaded\nprint(f\"[INFO] Loaded {len(data)} images.\")","metadata":{"_uuid":"4038c4dc-7d27-43e7-84bc-377ef15356e9","_cell_guid":"fe8bcd10-14d7-40af-9bf2-b432b7630a38","collapsed":false,"execution":{"iopub.status.busy":"2024-10-03T00:43:18.252984Z","iopub.execute_input":"2024-10-03T00:43:18.253553Z","iopub.status.idle":"2024-10-03T00:44:14.285825Z","shell.execute_reply.started":"2024-10-03T00:43:18.253473Z","shell.execute_reply":"2024-10-03T00:44:14.283912Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 2: Binarize Labels**","metadata":{"_uuid":"338a0569-fa93-4d7e-abc8-014e76e6d8a2","_cell_guid":"86bf9f86-405c-426b-8cd3-ec2b0fec463d","trusted":true}},{"cell_type":"code","source":"# Use MultiLabelBinarizer to one-hot encode the labels\nmlb = MultiLabelBinarizer()\nlabels = mlb.fit_transform(labels)\n\n# Display some label examples for verification\nprint(\"[INFO] Sample Labels after Binarization:\")\nprint(labels[:5])\nprint(\"Class labels:\", mlb.classes_)","metadata":{"_uuid":"9fd5fe4d-53e7-4247-ba28-78a72bd13ecc","_cell_guid":"41922467-67b6-4287-9983-2848acb88eb5","collapsed":false,"execution":{"iopub.status.busy":"2024-10-03T00:44:14.288057Z","iopub.execute_input":"2024-10-03T00:44:14.289100Z","iopub.status.idle":"2024-10-03T00:44:14.314542Z","shell.execute_reply.started":"2024-10-03T00:44:14.289036Z","shell.execute_reply":"2024-10-03T00:44:14.312722Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 3: Split the Data into Training and Testing Sets**","metadata":{"_uuid":"dd64123e-d8e6-43a7-92bb-7ef36f621288","_cell_guid":"327a376b-1adb-4fc9-a0a4-4028b0bd36ba","trusted":true}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the dataset into training and testing sets (80% train, 20% test)\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2, random_state=42)\n\nprint(f\"[INFO] Training data shape: {trainX.shape}\")\nprint(f\"[INFO] Testing data shape: {testX.shape}\")","metadata":{"_uuid":"4ac10a99-58e3-41cf-b7ca-a5e3c3c04287","_cell_guid":"9b21414d-6776-49f5-bbe6-ac4a556cb19d","collapsed":false,"execution":{"iopub.status.busy":"2024-10-03T00:44:14.317894Z","iopub.execute_input":"2024-10-03T00:44:14.318446Z","iopub.status.idle":"2024-10-03T00:44:14.542490Z","shell.execute_reply.started":"2024-10-03T00:44:14.318387Z","shell.execute_reply":"2024-10-03T00:44:14.540750Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 4: Build the Model**","metadata":{"_uuid":"8d349035-7044-4407-aafa-6a36a854c7b1","_cell_guid":"bafa355b-326a-4cd6-93d3-de2f902cbae7","trusted":true}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\n# Build a Sequential CNN model\nmodel = Sequential()\n\n# First convolutional layer\nmodel.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=IMAGE_DIMS, activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Second convolutional layer\nmodel.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Third convolutional layer\nmodel.add(Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Flatten and add fully connected layers\nmodel.add(Flatten())\nmodel.add(Dense(512, activation=\"relu\"))\nmodel.add(Dropout(0.5))\n\n# Output layer (multi-label classification - sigmoid activation)\nmodel.add(Dense(len(mlb.classes_), activation=\"sigmoid\"))\n\n# Compile the model\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\n# Print model summary\nprint(\"[INFO] Model summary:\")\nmodel.summary()","metadata":{"_uuid":"939bed9f-11ea-4646-8316-ed28f0fc3dff","_cell_guid":"11a95980-2368-4294-8af7-2ad0f900ddda","collapsed":false,"execution":{"iopub.status.busy":"2024-10-03T00:44:14.544272Z","iopub.execute_input":"2024-10-03T00:44:14.544747Z","iopub.status.idle":"2024-10-03T00:44:14.826917Z","shell.execute_reply.started":"2024-10-03T00:44:14.544703Z","shell.execute_reply":"2024-10-03T00:44:14.825240Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 5: Train the Model**","metadata":{"_uuid":"ce506493-ca64-455f-b796-9bfc9775b08c","_cell_guid":"f262e298-f5f3-4df6-b355-8c82fde40b35","trusted":true}},{"cell_type":"code","source":"# Define batch size and epochs\nEPOCHS = 25\nBS = 32  # Batch size\n\n# Train the model\nhistory = model.fit(\n    trainX, trainY, \n    validation_data=(testX, testY), \n    epochs=EPOCHS, \n    batch_size=BS, \n    verbose=1\n)\n\n# Save the model\nmodel.save(\"/kaggle/working/multi_label_model.h5\")","metadata":{"_uuid":"09686b3d-aa06-4928-9e17-b8ebb2aecedf","_cell_guid":"84031378-07af-46b6-a335-ccc77418880c","collapsed":false,"execution":{"iopub.status.busy":"2024-10-03T00:44:14.828715Z","iopub.execute_input":"2024-10-03T00:44:14.829105Z","iopub.status.idle":"2024-10-03T00:48:04.004202Z","shell.execute_reply.started":"2024-10-03T00:44:14.829067Z","shell.execute_reply":"2024-10-03T00:48:04.002582Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 6: Evaluate the Model**","metadata":{"_uuid":"e1daae00-1f64-4e7f-b0fa-90b9d228db34","_cell_guid":"ec4ece7d-a569-46e3-b1a8-66aaf45df9ef","trusted":true}},{"cell_type":"code","source":"# Evaluate the model\nprint(\"[INFO] Evaluating the model...\")\n(loss, accuracy) = model.evaluate(testX, testY, batch_size=BS, verbose=1)\nprint(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")","metadata":{"_uuid":"aaed4bb3-9a2d-4d54-aa9d-5c813ed6a25b","_cell_guid":"c04bf034-4385-45c1-9c0a-d942caf508bd","collapsed":false,"execution":{"iopub.status.busy":"2024-10-03T00:48:04.006019Z","iopub.execute_input":"2024-10-03T00:48:04.006458Z","iopub.status.idle":"2024-10-03T00:48:04.742259Z","shell.execute_reply.started":"2024-10-03T00:48:04.006414Z","shell.execute_reply":"2024-10-03T00:48:04.740849Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 7: Visualize the Training History**","metadata":{"_uuid":"1523e43e-7a30-4766-b637-50e6d9a5ed13","_cell_guid":"a51941aa-1faa-44fc-abf5-c79c51c50ff3","trusted":true}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot training and validation accuracy/loss\nplt.figure(figsize=(12, 4))\n\n# Accuracy plot\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='upper left')\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='upper left')\n\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"bea0ccbd-3d50-4db7-9ae1-67286d4e1f61","_cell_guid":"027cef97-24b7-4c4e-ae66-9c8e3f0fa03e","collapsed":false,"execution":{"iopub.status.busy":"2024-10-03T00:48:04.744189Z","iopub.execute_input":"2024-10-03T00:48:04.744819Z","iopub.status.idle":"2024-10-03T00:48:05.516888Z","shell.execute_reply.started":"2024-10-03T00:48:04.744748Z","shell.execute_reply":"2024-10-03T00:48:05.515263Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Make Predictions on New Images(Examples)**","metadata":{"_uuid":"5804e1e0-c1ce-4e77-95e5-7b84c6d3cef8","_cell_guid":"76899319-d9b0-4f8a-b32f-22b3a5f2b1af","trusted":true}},{"cell_type":"code","source":"# The model has already been trained and saved\nmodel_path = \"/kaggle/working/multi_label_model.h5\"\nmodel = load_model(model_path)\n\n# 2. Load the MultiLabelBinarizer\nmlb_path = '/kaggle/working/mlb.pickle'\nwith open(mlb_path, 'rb') as f:\n    mlb = pickle.load(f)\n\n# 3. Preprocess a new image for prediction\ndef prepare_image(image_path):\n    image = cv2.imread(image_path)\n    image = cv2.resize(image, (IMAGE_DIMS[0], IMAGE_DIMS[1]))\n    image = np.array(image, dtype=\"float\") / 255.0\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    return image\n\n# Example image path\nimage_path =  \"/kaggle/input/keras-multi-label/keras-multi-label/examples/example_05.jpg\"\nimage = prepare_image(image_path)\n\n# 4. Make a prediction on the image\npreds = model.predict(image)\n\n# Keep only the first 5 columns of predictions\npreds = preds[:, :5]  # Adjust to match the expected number of classes\n\n# Print raw predictions for debugging\nprint(f\"[DEBUG] Raw predictions: {preds}\")\n\n# Convert predicted probabilities to binary predictions with a lower threshold\nthreshold = 0.3  # Consider lowering the threshold to see if it helps\nbinary_preds = (preds >= threshold).astype(int)  # Apply threshold\n\n# 5. Decode the prediction\npredicted_labels = mlb.inverse_transform(binary_preds)\nprint(f\"[INFO] Predicted labels: {predicted_labels}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-03T00:55:30.379200Z","iopub.execute_input":"2024-10-03T00:55:30.379754Z","iopub.status.idle":"2024-10-03T00:55:30.725935Z","shell.execute_reply.started":"2024-10-03T00:55:30.379707Z","shell.execute_reply":"2024-10-03T00:55:30.724409Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n[DEBUG] Raw predictions: [[0.16190077 0.04690529 0.42183858 0.0091376  0.01166103]]\n[INFO] Predicted labels: [('blue_jeans',)]\n","output_type":"stream"}]},{"cell_type":"code","source":"# The model has already been trained and saved\nmodel_path = \"/kaggle/working/multi_label_model.h5\"\nmodel = load_model(model_path)\n\n# Load the MultiLabelBinarizer\nmlb_path = '/kaggle/working/mlb.pickle'\nwith open(mlb_path, 'rb') as f:\n    mlb = pickle.load(f)\n\n# Preprocess a new image for prediction\ndef prepare_image(image_path):\n    image = cv2.imread(image_path)\n    image = cv2.resize(image, (IMAGE_DIMS[0], IMAGE_DIMS[1]))\n    image = np.array(image, dtype=\"float\") / 255.0\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    return image\n\n# Example image path\nimage_path = \"/kaggle/input/keras-multi-label/keras-multi-label/examples/example_05.jpg\"\nimage = prepare_image(image_path)\n\n# Make a prediction on the image\npreds = model.predict(image)\n\n# Adjust the predictions based on the number of classes\nnum_classes = len(mlb.classes_)\npreds = preds[:, :num_classes]  # Ensure we're using the correct number of classes\n\n# Define a range of thresholds to test\nthresholds = [0.3, 0.4]  # Add more thresholds as needed\n\n# Loop through each threshold and make predictions\nfor threshold in thresholds:\n    binary_preds = (preds >= threshold).astype(int)  # Apply threshold\n    predicted_labels = mlb.inverse_transform(binary_preds)\n    print(f\"[INFO] Predicted labels at threshold {threshold}: {predicted_labels}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-03T00:59:57.314439Z","iopub.execute_input":"2024-10-03T00:59:57.314945Z","iopub.status.idle":"2024-10-03T00:59:58.020735Z","shell.execute_reply.started":"2024-10-03T00:59:57.314897Z","shell.execute_reply":"2024-10-03T00:59:58.019180Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n[INFO] Predicted labels at threshold 0.3: [('blue_jeans',)]\n[INFO] Predicted labels at threshold 0.4: [('blue_jeans',)]\n","output_type":"stream"}]},{"cell_type":"code","source":"# The model has already been trained and saved\nmodel_path = \"/kaggle/working/multi_label_model.h5\"\nmodel = load_model(model_path)\n\n# Load the MultiLabelBinarizer\nmlb_path = '/kaggle/working/mlb.pickle'\nwith open(mlb_path, 'rb') as f:\n    mlb = pickle.load(f)\n\n# Preprocess a new image for prediction\ndef prepare_image(image_path):\n    image = cv2.imread(image_path)\n    image = cv2.resize(image, (IMAGE_DIMS[0], IMAGE_DIMS[1]))\n    image = np.array(image, dtype=\"float\") / 255.0\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    return image\n\n# Example image path\nimage_path = \"/kaggle/input/keras-multi-label/keras-multi-label/examples/example_04.jpg\"\nimage = prepare_image(image_path)\n\n# Make a prediction on the image\npreds = model.predict(image)\n\n# Adjust the predictions based on the number of classes\nnum_classes = len(mlb.classes_)\npreds = preds[:, :num_classes]  # Ensure we're using the correct number of classes\n\n# Define a range of thresholds to test\nthresholds = [0.3, 0.4]  # Add more thresholds as needed\n\n# Loop through each threshold and make predictions\nfor threshold in thresholds:\n    binary_preds = (preds >= threshold).astype(int)  # Apply threshold\n    predicted_labels = mlb.inverse_transform(binary_preds)\n    print(f\"[INFO] Predicted labels at threshold {threshold}: {predicted_labels}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-03T00:59:48.449474Z","iopub.execute_input":"2024-10-03T00:59:48.450730Z","iopub.status.idle":"2024-10-03T00:59:48.857943Z","shell.execute_reply.started":"2024-10-03T00:59:48.450673Z","shell.execute_reply":"2024-10-03T00:59:48.856713Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n[INFO] Predicted labels at threshold 0.3: [('blue_dress',)]\n[INFO] Predicted labels at threshold 0.4: [('blue_dress',)]\n","output_type":"stream"}]}]}